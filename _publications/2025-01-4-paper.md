---
title: "La contribution des LLM à l'extraction de relations dans le domaine financier"
collection: publications
type: "Publication"
permalink: /publications/2025-01-4-paper
excerpt: "L'extraction de relations (RE) est une tâche clé en traitement du langage naturel, visant à identifier les relations sémantiques entre des entités dans un texte. Les méthodes traditionnelles supervisées entraînent des modèles pour annoter les entités et prédire leurs relations. Récemment, cette tâche a évolué vers un problème séquence-à-séquence, où les relations sont converties en chaînes cibles générées à partir du texte d'entrée. Les modèles de langage, de plus en plus utilisés dans ce domaine, ont permis des avancées notables avec divers niveaux de raffinement. L'objectif de l'étude présentée ici est d'évaluer l'apport des grands modèles de langue (LLM) dans la tâche d'extraction de relations dans un domaine spécifique (ici le domaine économique), par rapport à des modèles de langue plus petits. Pour ce faire, nous avons considéré comme baseline un modèle reposant sur l'architecture BERT et entraîné dans ce domaine, et quatre LLMs, à savoir FinGPT spécifique au domaine de la finance, et XLNet, ChatGLM2 et LLama3 qui sont généralistes. Tous ces modèles ont été évalués sur une même tâche d'extraction, avec, pour les LLM généralistes, des affinements par few-shot learning et fine-tuning. Les expériences ont montré que les meilleures performances en termes de F-score ont été obtenues avec des LLM affinés, Llama3 obtenant les meilleures performances."
venue: "Extraction et Gestion des Connaissances EGC2025 (pp. 279-286)"
location: "Strasbourg, France"
date: 2025-01-01
citation: "M Mohamed Ettaleb, Mouna Kamel, Véronique Moriceau, Nathalie Aussenac-Gilles. La contribution des LLM à l'extraction de relations dans le domaine financier. Extraction et Gestion des Connaissances EGC2025, Thomas Guyet; Baptiste Lafabrègue; Aurélie Leborgne, Jan 2025, Strasbourg, France. pp.279-286. ⟨hal-04940352⟩"
---
 L'extraction de relations (RE) est une tâche clé en traitement du langage naturel, visant à identifier les relations sémantiques entre des entités dans un texte. Les méthodes traditionnelles supervisées entraînent des modèles pour annoter les entités et prédire leurs relations. Récemment, cette tâche a évolué vers un problème séquence-à-séquence, où les relations sont converties en chaînes cibles générées à partir du texte d'entrée. Les modèles de langage, de plus en plus utilisés dans ce domaine, ont permis des avancées notables avec divers niveaux de raffinement. L'objectif de l'étude présentée ici est d'évaluer l'apport des grands modèles de langue (LLM) dans la tâche d'extraction de relations dans un domaine spécifique (ici le domaine économique), par rapport à des modèles de langue plus petits. Pour ce faire, nous avons considéré comme baseline un modèle reposant sur l'architecture BERT et entraîné dans ce domaine, et quatre LLMs, à savoir FinGPT spécifique au domaine de la finance, et XLNet, ChatGLM2 et LLama3 qui sont généralistes. Tous ces modèles ont été évalués sur une même tâche d'extraction, avec, pour les LLM généralistes, des affinements par few-shot learning et fine-tuning. Les expériences ont montré que les meilleures performances en termes de F-score ont été obtenues avec des LLM affinés, Llama3 obtenant les meilleures performances. 

[Download paper here](https://hal.science/hal-04940352v1/document)
